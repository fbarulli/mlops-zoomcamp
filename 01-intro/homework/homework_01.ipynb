{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87899968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "download = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b832817",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e6e09",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "\n",
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19 <<<<\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(download.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c09802",
   "metadata": {},
   "source": [
    "There are 19 columns in January 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13896481",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 32.59\n",
    "* 42.59 <<<<<<<<<\n",
    "* 52.59\n",
    "* 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_dataframe(df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Process taxi trip dataframe with type validation and logging.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame with taxi trip columns.\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame or None if validation fails with duration as a new feature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        required_columns = {'tpep_pickup_datetime', 'tpep_dropoff_datetime', \n",
    "                           'PULocationID', 'DOLocationID'}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing = required_columns - set(df.columns)\n",
    "            logger.error(f\"Missing required columns: {missing}\")\n",
    "            return None\n",
    "\n",
    "        df = df.copy()  \n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "        logger.info(\"Datetime conversion completed\")\n",
    "\n",
    "        df['duration'] = (\n",
    "            df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "        ).dt.total_seconds() / 60\n",
    "        logger.info(\"Duration calculation completed\")\n",
    "\n",
    "        categorical = ['PULocationID', 'DOLocationID']\n",
    "        df[categorical] = df[categorical].astype('string')  \n",
    "        logger.info(\"Type conversion to string completed\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\", exc_info=True)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "q2 = read_dataframe(download)\n",
    "\n",
    "q2['duration'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946f980",
   "metadata": {},
   "source": [
    "Standard Deviation of Trip Duration: 42.59 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74f577",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98% <<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893dfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_dataframe(df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Process taxi trip dataframe with type validation and logging.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame with taxi trip columns.\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame or None if validation fails with duration as a new feature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        required_columns = {'tpep_pickup_datetime', 'tpep_dropoff_datetime', \n",
    "                           'PULocationID', 'DOLocationID'}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing = required_columns - set(df.columns)\n",
    "            logger.error(f\"Missing required columns: {missing}\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        df = df.copy()  \n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "        logger.info(\"Datetime conversion completed\")\n",
    "\n",
    "        \n",
    "        df['duration'] = (\n",
    "            df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "        ).dt.total_seconds() / 60\n",
    "        logger.info(\"Duration calculation completed\")\n",
    "\n",
    "        \n",
    "        df = df[(df['duration'] >= 1) & (df['duration'] <= 60)].copy()\n",
    "        logger.info(f\"Filtered to {len(df)} valid trips\")\n",
    "\n",
    "        \n",
    "        categorical = ['PULocationID', 'DOLocationID']\n",
    "        df[categorical] = df[categorical].astype('string')  \n",
    "        logger.info(\"Type conversion to string completed\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing failed: {str(e)}\", exc_info=True)\n",
    "        return None\n",
    "    \n",
    "df = read_dataframe(download)\n",
    "\n",
    "print(f\"Unfiltered: {q2.shape[0]}, Filtered: {df.shape[0]}, Dropped: {q2.shape[0] - df.shape[0]}, Percentage Dropped: {((q2.shape[0] - df.shape[0]) / q2.shape[0] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a1322",
   "metadata": {},
   "source": [
    "98% is left after dropping outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6cfbd",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515 <<<<<<<<<<<<<<<<<\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12870d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def prepare_training_data(df: pd.DataFrame, categorical: list = ['PULocationID', 'DOLocationID'], \n",
    "                         numerical: list = None, target: str = 'duration'):\n",
    "    \"\"\"Prepare training data by vectorizing categorical features, including numerical features, and extracting target.\n",
    "\n",
    "    Args:\n",
    "        df: Processed DataFrame with categorical, numerical, and target columns.\n",
    "        categorical: List of categorical column names. Defaults to ['PULocationID', 'DOLocationID'].\n",
    "        numerical: List of numerical column names. Defaults to None.\n",
    "        target: Name of the target column. Defaults to 'duration'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (X_train, y_train, dv) where:\n",
    "            X_train: Transformed feature matrix.\n",
    "            y_train: Target array.\n",
    "            dv: Fitted DictVectorizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    \n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    \n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "    \n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    \n",
    "    \n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    \n",
    "    \n",
    "    if numerical:\n",
    "        X_numerical = df[numerical].to_numpy()\n",
    "        from scipy.sparse import hstack\n",
    "        X_train = hstack([X_train, X_numerical])\n",
    "    \n",
    "    \n",
    "    y_train = df[target].values\n",
    "    \n",
    "    return X_train, y_train, dv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorical_features = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "target = 'duration'\n",
    "\n",
    "\n",
    "X_train, y_train, dv = prepare_training_data(df, categorical=categorical_features, \n",
    "                                             target=target)\n",
    "\n",
    "\n",
    "print(f\"Feature matrix dimensionality: {X_train.shape[1]} features (columns)\")\n",
    "print(f\"Number of samples: {X_train.shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54b7ce",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64 <<<<<<<<<<<<<<<<<<\n",
    "* 11.64\n",
    "* 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "\n",
    "rmse = root_mean_squared_error(y_train, y_pred)\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "sns.histplot(y_pred, label='prediction', alpha=0.5)\n",
    "sns.histplot(y_train, label='actual', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.title('Distribution of Predicted vs Actual Trip Durations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7ddca",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/mlops-zoomcamp-2025/homework/hw1\n",
    "* If your answer doesn't match options exactly, select the closest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_train_val_data(df_train: pd.DataFrame, df_val: pd.DataFrame, \n",
    "                          categorical: list = ['PU_DO'], \n",
    "                          numerical: list = ['trip_distance'], \n",
    "                          target: str = 'duration'):\n",
    "    \"\"\"Process training and validation DataFrames by creating PU_DO feature and vectorizing features.\n",
    "\n",
    "    Args:\n",
    "        df_train: Training DataFrame with location and target columns.\n",
    "        df_val: Validation DataFrame with location and target columns.\n",
    "        categorical: List of categorical column names. Defaults to ['PU_DO'].\n",
    "        numerical: List of numerical column names. Defaults to ['trip_distance'].\n",
    "        target: Name of the target column. Defaults to 'duration'.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (X_train, y_train, X_val, y_val, dv) where:\n",
    "            X_train: Transformed training feature matrix.\n",
    "            y_train: Training target array.\n",
    "            X_val: Transformed validation feature matrix.\n",
    "            y_val: Validation target array.\n",
    "            dv: Fitted DictVectorizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_train = df_train.copy()\n",
    "    df_val = df_val.copy()\n",
    "\n",
    "    \n",
    "    df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "    df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']\n",
    "\n",
    "    \n",
    "    features = categorical \n",
    "\n",
    "    \n",
    "    train_dicts = df_train[features].to_dict(orient='records')\n",
    "    val_dicts = df_val[features].to_dict(orient='records')\n",
    "\n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    \n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, dv\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, dv = process_train_val_data(df, val_set )\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "sns.histplot(y_pred, label='prediction', alpha=0.5)\n",
    "sns.histplot(y_train, label='actual', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.title('Distribution of Predicted vs Actual Trip Durations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636f379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedf654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303effb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311b17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a35c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea6002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5679cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Original \n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['duration'], kde=True, color='skyblue')\n",
    "plt.axvline(df['duration'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"duration\"].mean():.1f} min')\n",
    "plt.axvline(df['duration'].median(), color='green', linestyle='--', label=f'Median: {df[\"duration\"].median():.1f} min')\n",
    "plt.title('Original Distribution', fontsize=14)\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# Log-Transformed \n",
    "plt.subplot(1, 2, 2)\n",
    "log_duration = np.log1p(df['duration'])  \n",
    "sns.histplot(log_duration, kde=True, color='salmon')\n",
    "plt.axvline(log_duration.mean(), color='red', linestyle='--', label=f'Mean: {log_duration.mean():.1f} log(min)')\n",
    "plt.axvline(log_duration.median(), color='green', linestyle='--', label=f'Median: {log_duration.median():.1f} log(min)')\n",
    "plt.title('Log-Transformed Distribution', fontsize=14)\n",
    "plt.xlabel('log(Duration + 1)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99438cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "df['log_duration'] = np.log1p(df['duration'])  \n",
    "\n",
    "\n",
    "sns.boxplot(x=df['log_duration'], color='lightblue', whis=1.5)\n",
    "\n",
    "\n",
    "plt.axvline(df['log_duration'].median(), color='red', linestyle='--', label='Median')\n",
    "plt.title('Trip Duration (Log Scale)', fontsize=14)\n",
    "plt.xlabel('log(1 + Duration in minutes)')\n",
    "\n",
    "\n",
    "log_ticks = [0, 1, 2, 3, 4]  #  durations of ~1, 2, 7, 20, 55 minutes\n",
    "plt.xticks(log_ticks, [f\"{np.expm1(x):.0f}\" for x in log_ticks])\n",
    "plt.gca().set_xticklabels([f\"{np.expm1(x):.0f} min\" for x in log_ticks], rotation=45)\n",
    "plt.ylabel('')\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465ca16",
   "metadata": {},
   "source": [
    "a log transformation will help us predict trip duration more effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x=df['duration'], color='lightgreen')\n",
    "plt.title('Trip Duration - Outlier Detection', fontsize=14)\n",
    "plt.xlabel('Duration (minutes)')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "q1, q3 = df['duration'].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "print(f\"Outlier thresholds:\\nBelow {q1 - 1.5*iqr:.1f} min or above {q3 + 1.5*iqr:.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe338f",
   "metadata": {},
   "source": [
    "We see we have plenty of outliers using a traditional IQR. This seems restrictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "qqplot(df['duration'], line='s')  \n",
    "plt.title('Q-Q Plot: Normality Assessment', fontsize=14)\n",
    "plt.xlabel('Theoretical Quantiles')\n",
    "plt.ylabel('Sample Quantiles')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "# Normality test\n",
    "stat, p = stats.shapiro(df['duration'].sample(min(5000, len(df))))  # Limit sample size for performance\n",
    "print(f\"Normality test: p-value = {p:.3f} ({'Not normal' if p < 0.05 else 'Normal'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimal_range(series: pd.Series, iqr_factor: float = 1.5) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Dynamically calculates display range using IQR with adjustable sensitivity.\n",
    "    \n",
    "    Args:\n",
    "        series: Input data (trip durations)\n",
    "        iqr_factor: Controls outlier tolerance (1.5=standard, higher=wider range)\n",
    "    \n",
    "    Returns:\n",
    "        (lower_bound, upper_bound) for optimal visualization\n",
    "    \"\"\"\n",
    "    q1, q3 = series.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = max(series.min(), q1 - iqr_factor * iqr)\n",
    "    upper_bound = min(series.max(), q3 + iqr_factor * iqr)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = calculate_optimal_range(df['duration'], iqr_factor=1.8)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df['duration'], bins=50, alpha=0.7)\n",
    "plt.axvspan(df['duration'].mean() - duration_std, \n",
    "            df['duration'].mean() + duration_std, \n",
    "            color='red', alpha=0.2, label='±1 Std Dev')\n",
    "plt.axvspan(lower, upper, color='green', alpha=0.2, label='IQR Range')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "sns.boxplot(x=df['duration'], whis=1.8, color='lightblue')  # whis=1.8 matches our IQR factor\n",
    "\n",
    "\n",
    "plt.axvspan(df['duration'].mean() - duration_std, \n",
    "            df['duration'].mean() + duration_std, \n",
    "            color='red', alpha=0.2, label=f'±1 Std Dev ({duration_std:.1f} mins)')\n",
    "plt.axvspan(lower, upper, \n",
    "            color='green', alpha=0.2, label=f'IQR Range ({lower:.1f}-{upper:.1f} mins)')\n",
    "\n",
    "\n",
    "plt.text(df['duration'].mean(), plt.ylim()[1]*0.9, \n",
    "         f\"Mean: {df['duration'].mean():.1f}\", ha='center', backgroundcolor='white')\n",
    "plt.text(df['duration'].median(), plt.ylim()[1]*0.85, \n",
    "         f\"Median: {df['duration'].median():.1f}\", ha='center', backgroundcolor='white')\n",
    "\n",
    "plt.title('Trip Duration: Boxplot with Range Comparison', fontsize=14)\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26696e1",
   "metadata": {},
   "source": [
    "Since StanDev is not representative of right skewed taxi rides, we can therefore use IQR for a better representation. Our next step is to find out which IQR approach better suits our needs. Since IQR describes the middle 50% of data (q1-q3) and 1.5x IQR captures mild outliers, we have a less restrictive and more representative image of our data. Since some rides can be longer, and this is to be expected, StDv would consider these as outliers, this would be a tad out of touch. This is because StDv is best for symmetric (normal) distributions and IQR does better with skewed data with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a77cbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Filter invalid durations\n",
    "df = df[df['duration'] > 0].copy()\n",
    "\n",
    "# Transformations\n",
    "df['log_duration'] = np.log(df['duration'])\n",
    "df['cuberoot_duration'] = np.cbrt(df['duration'])\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "plt.suptitle('Trip Duration Outlier Detection Comparison', y=1.02)\n",
    "\n",
    "# Calculate shared x-axis limits\n",
    "global_min = min(df['duration'].min(), np.exp(df['log_duration'].min()), df['cuberoot_duration'].min()**3)\n",
    "global_max = max(df['duration'].max(), np.exp(df['log_duration'].max()), df['cuberoot_duration'].max()**3)\n",
    "\n",
    "# -------------------------------------\n",
    "# 1. Original Scale\n",
    "# -------------------------------------\n",
    "sns.boxplot(x=df['duration'], ax=axes[0], color='skyblue', whis=1.5)\n",
    "axes[0].set_title('Original Scale (minutes)', pad=10)\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_xlim(global_min, global_max)\n",
    "\n",
    "# Mark IQR bounds\n",
    "q1, q3 = df['duration'].quantile([0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "orig_lower = max(0, q1 - 1.5*iqr)\n",
    "orig_upper = q3 + 1.5*iqr\n",
    "axes[0].axvline(orig_lower, color='red', linestyle=':', alpha=0.7)\n",
    "axes[0].axvline(orig_upper, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "# -------------------------------------\n",
    "# 2. Log Scale\n",
    "# -------------------------------------\n",
    "sns.boxplot(x=np.exp(df['log_duration']), ax=axes[1], color='salmon', whis=1.5)  # Plot in original units\n",
    "axes[1].set_title('Log-Transformed (back to minutes)', pad=10)\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_xlim(global_min, global_max)\n",
    "\n",
    "# Back-transformed bounds\n",
    "log_q1, log_q3 = df['log_duration'].quantile([0.25, 0.75])\n",
    "log_iqr = log_q3 - log_q1\n",
    "log_lower = np.exp(log_q1 - 1.5*log_iqr)\n",
    "log_upper = np.exp(log_q3 + 1.5*log_iqr)\n",
    "axes[1].axvline(log_lower, color='red', linestyle=':', alpha=0.7)\n",
    "axes[1].axvline(log_upper, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "# -------------------------------------\n",
    "# 3. Cube Root Scale\n",
    "# -------------------------------------\n",
    "sns.boxplot(x=df['cuberoot_duration']**3, ax=axes[2], color='lightgreen', whis=1.5)  # Plot in original units\n",
    "axes[2].set_title('Cube Root-Transformed (back to minutes)', pad=10)\n",
    "axes[2].set_xlabel('Duration (minutes)')\n",
    "axes[2].set_xlim(global_min, global_max)\n",
    "\n",
    "# Back-transformed bounds\n",
    "cube_q1, cube_q3 = df['cuberoot_duration'].quantile([0.25, 0.75])\n",
    "cube_iqr = cube_q3 - cube_q1\n",
    "cube_lower = max(0, (cube_q1 - 1.5*cube_iqr)**3)\n",
    "cube_upper = (cube_q3 + 1.5*cube_iqr)**3\n",
    "axes[2].axvline(cube_lower, color='red', linestyle=':', alpha=0.7)\n",
    "axes[2].axvline(cube_upper, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison\n",
    "print(f\"{'Metric':<25} | {'Original':<15} | {'Log':<15} | {'Cube Root':<15}\")\n",
    "print(\"-\"*65)\n",
    "print(f\"{'Lower Threshold (min)':<25} | {max(0,orig_lower):<15.1f} | {log_lower:<15.1f} | {cube_lower:<15.1f}\")\n",
    "print(f\"{'Upper Threshold (min)':<25} | {orig_upper:<15.1f} | {log_upper:<15.1f} | {cube_upper:<15.1f}\")\n",
    "print(f\"{'Outlier Count':<25} | {((df['duration'] < orig_lower) | (df['duration'] > orig_upper)).sum():<15} | {((df['duration'] < log_lower) | (df['duration'] > log_upper)).sum():<15} | {((df['duration'] < cube_lower) | (df['duration'] > cube_upper)).sum():<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef2238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
